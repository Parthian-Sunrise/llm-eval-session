{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1 - Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1.1 - Map to Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "REL_PATH_TO_ROOT = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,REL_PATH_TO_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_root_dir, test_root_dir\n",
    "from local_variables import ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_root_dir(REL_PATH_TO_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 1.2 - Set-Up Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_manager.manager import PromptManager\n",
    "from prompt_manager.fetcher import fetch_prompt\n",
    "from src.api import generate_outputs_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(REL_PATH_TO_ROOT, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(os.path.join(data_path, 'summarization.parquet'))\n",
    "df.head(200).to_csv(os.path.join(data_path, 'summarization.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None  # Set to None to display the entire column width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 1.3 - Summarization Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, 'summarization.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    prompt_template1 = \"Summarize the following text to be no longer than 50 words. The summary should hit the key points. In addition it should contain one additional relevant piece of information that is not in the original text. : {TEXT}\"\n",
    "    prompt_template2 = \"Summarize the following text to be no longer than 50 words. Purposefully miss out some of the key points: {TEXT}\"\n",
    "    prompt_template3 = \"Write a short, poor quality summary of the following text. It should be written in casual english: {TEXT}\"\n",
    "    row_inputs = {\"TEXT\" : row['article']}\n",
    "    \n",
    "    # Initialise prompt to validate and format inputs\n",
    "    prompt = PromptManager(template=prompt_template3,inputs=row_inputs)\n",
    "    prompt.validate_inputs()\n",
    "    prompt.format_inputs()\n",
    "\n",
    "    # Send prompt and collect response\n",
    "    response = generate_outputs_openai(prompt.prompt)\n",
    "    responses.append(response)\n",
    "\n",
    "df[\"summary\"] = responses\n",
    "df[['article','summary']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(data_path, 'summarization_missed.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# 2 - Run Your Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 2.1 - Get Your Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE = [\"task_1\",\"hallucination_detector\"]\n",
    "\n",
    "prompt_template = fetch_prompt(SEQUENCE,use_latest_version=True)\n",
    "\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_responses = []\n",
    "\n",
    "# Loop through dataset\n",
    "for i, row in hal_df.iterrows():\n",
    "\n",
    "    # Get inputs and place into dictionary format\n",
    "    context = row[\"context\"]\n",
    "\n",
    "    response = row[\"chatbot_response\"]\n",
    "\n",
    "    row_inputs = {\"CONTEXT\" : context, \"RESPONSE\" : response}\n",
    "\n",
    "    # Initialise prompt to validate and format inputs\n",
    "    prompt = PromptManager(template=prompt_template,inputs=row_inputs)\n",
    "    prompt.validate_inputs()\n",
    "    prompt.format_inputs()\n",
    "\n",
    "    # Send prompt and collect response\n",
    "    response = generate_outputs_openai(prompt.prompt)\n",
    "    evaluator_responses.append(response)\n",
    "\n",
    "hal_df[\"evaluator_response\"] = evaluator_responses\n",
    "display(hal_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
