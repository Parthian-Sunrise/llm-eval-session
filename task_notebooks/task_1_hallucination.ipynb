{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Task 1: Hallucination Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Welcome to task 1!\n",
    "\n",
    "Hallucination refers to the phenomenon where a language model generates information that is false, inaccurate, or fabricated, even though the output may sound plausible or confident. \n",
    "\n",
    "Hallucinations occur because the model predicts text based on patterns in its training data rather than confirming factual correctness or grounding the response in reality.\n",
    "\n",
    "In a Question-Answer task, an LLM might hallucinate for any of the following reasons:\n",
    "\n",
    "- Lack of Knowledge: the model may not have seen information related to the question in it's training, leading it to 'guess' the answer\n",
    "- Training on Unverified Data: Inaccuracies in training datasets may follow through to an incorrect answer\n",
    "- Ambiguous prompts: Vague or poor quality questions can cause the model to make assumptions about the user's intent\n",
    "- Lack of Grounding: LLMs lack a mechanism to validate their outputs, which can lead to creative but unfounded responses.\n",
    "\n",
    "Even when provided with a reference source of information ('context'), LLMs may still hallucinate for the following reasons:\n",
    "- Lack of clear instructions (prompt is important!)\n",
    "- Loss of focus on the context and over-reliance on training data\n",
    "- Focus on probability over truth: LLMs generate responses based on the most likely next word sequence, which might prioritize plausibility over factual accuracy if the model predicts a more likely (but incorrect) continuation than the actual answer\n",
    "- Failure to align context with question, especially if context is complex\n",
    "\n",
    "Hallucinations are a critical challenge in AI, especially in applications where accuracy and reliability are essential.\n",
    "\n",
    "**In this task you will build an LLM Judge to analyse whether the provided answer is a hallucination based on a relevant source of information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Environment Set Up \n",
    "\n",
    "Run the following cell. \n",
    "If there are no issues, you will get the message 'Root directory set up correctly!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -qq -r ../requirements.txt\n",
    "\n",
    "REL_PATH_TO_ROOT = \"../\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0,REL_PATH_TO_ROOT)\n",
    "\n",
    "from src.utils import get_root_dir, test_root_dir\n",
    "from local_variables import ROOT_DIR\n",
    "\n",
    "test_root_dir(REL_PATH_TO_ROOT)\n",
    "\n",
    "from prompt_manager.manager import PromptManager\n",
    "from prompt_manager.fetcher import fetch_prompt\n",
    "from src.api import generate_outputs_openai\n",
    "from src.image_display import display_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Task Background\n",
    "\n",
    "Below is the initial ask from the AskAI team as well as an explanation of the dataset they have provided you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "#### The Ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(f\"{get_root_dir()}/task_images/task_1_desc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(f\"{get_root_dir()}/task_images/task_1_data.png\",max_size=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "The dataset contains 50 question-answer pairs.\n",
    "\n",
    "For each question-answer pair, we have provided ground truth labels for hallucination. \n",
    "\n",
    "A label of 1 suggests this answer is incorrect and is a hallucination.\n",
    "A label of 0 suggests the answer is correct.\n",
    "\n",
    "There are 25 question-answer pairs with label 1 and 25 pairs with label 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join(REL_PATH_TO_ROOT, \"data/hallucination.csv\")\n",
    "hallucination_df = pd.read_csv(input_path).drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Task: Build LLM-as-a-judge\n",
    "\n",
    "Craft a prompt that aims to correctly categorise whether the response is a correct answer or a hallucinated one.\n",
    "\n",
    "The **inputs** to your LLM Judge is the context (i.e. relevant_knowledge and user_question) and the response.\n",
    "\n",
    "The **output** from your LLM Judge should be a boolean 1/0 categorisation\n",
    "\n",
    "An initial prompt has already been created for you to start from. This can be found under prompts/task_1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Load the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE = [\"task_1\",\"hallucination_detector\"]\n",
    "\n",
    "prompt_template = fetch_prompt(SEQUENCE,use_latest_version=True)\n",
    "\n",
    "print(f\"Current LLM Judge Prompt:\\n------------------------\\n{prompt_template}\\n------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of rows to process\n",
    "num_rows = 50  # Set to the desired number of rows or None to run all\n",
    "\n",
    "# Define context based on our data for the initial prompt\n",
    "hallucination_df[\"context\"] = hallucination_df[\"relevant_knowledge\"] + hallucination_df[\"user_question\"]\n",
    "\n",
    "# Define response based on our data for the initial prompt\n",
    "hallucination_df[\"response\"] = hallucination_df[\"chatbot_answer\"]\n",
    "\n",
    "# Determine the total number of rows in the DataFrame\n",
    "total_rows = len(hallucination_df)\n",
    "\n",
    "# Check if num_rows is None, indicating that we want to process all rows\n",
    "if num_rows is None:\n",
    "    rows_to_process = total_rows\n",
    "else:\n",
    "    # Otherwise, set rows_to_process to the smaller of num_rows and total_rows\n",
    "    rows_to_process = min(num_rows, total_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of model responses\n",
    "evaluator_responses = []\n",
    "\n",
    "# Loop through dataset with a row limit if specified\n",
    "for i, (_, row) in enumerate(tqdm(hallucination_df.head(rows_to_process).iterrows())):\n",
    "    \n",
    "    # Get inputs and place into dictionary format\n",
    "    context = row[\"context\"]\n",
    "    response = row[\"response\"]\n",
    "    row_inputs = {\"CONTEXT\": context, \"RESPONSE\": response}\n",
    "\n",
    "    # Initialise prompt to validate and format inputs\n",
    "    prompt = PromptManager(template=prompt_template, inputs=row_inputs)\n",
    "    prompt.validate_inputs()\n",
    "    prompt.format_inputs()\n",
    "\n",
    "    # Send prompt and collect response\n",
    "    response = generate_outputs_openai(prompt.prompt)\n",
    "    evaluator_responses.append(response)\n",
    "\n",
    "# Create a new DataFrame with only processed rows and add the evaluator responses\n",
    "processed_df = hallucination_df.head(rows_to_process).copy()\n",
    "processed_df[\"evaluator_response\"] = evaluator_responses\n",
    "\n",
    "# Display the resulting processed DataFrame\n",
    "display(processed_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Now, calculate the accuracy of your LLM-as-a-judge. How does it look? \n",
    "\n",
    "Can you refine the prompt to increase the agreement with the ground truth labels? \n",
    "\n",
    "Try modifying the prompt in prompts/task_1 and re-running the above cells.\n",
    "\n",
    "Make sure you always include the input placeholders {CONTEXT} and {RESPONSE} in your prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df[\"agreement\"] = (processed_df[\"is_hallucination_error_ground_truth\"].astype(str) == processed_df[\"evaluator_response\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_agreement = processed_df[\"agreement\"].mean()\n",
    "percentage_agreement_rounded = round(100 * percentage_agreement, 1)\n",
    "print(f\"\\nYour LLM Judge achieved {percentage_agreement_rounded}% agreement!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## End of Task 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
